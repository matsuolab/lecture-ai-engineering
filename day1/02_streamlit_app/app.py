# app.py
import streamlit as st
import ui                   # UIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import llm                  # LLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import database             # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import metrics              # è©•ä¾¡æŒ‡æ¨™ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import data                 # ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import torch
from transformers import pipeline
from config import MODEL_NAME
from huggingface_hub import HfFolder

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š ---
st.set_page_config(page_title="ğŸ¤– Gemma Chatbot", layout="wide", page_icon="ğŸ¤–")

# --- åˆæœŸåŒ–å‡¦ç† ---
metrics.initialize_nltk()
database.init_db()
data.ensure_initial_data()

# --- ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨ï¼‰ ---
@st.cache_resource
def load_model():
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        with st.spinner(f"ãƒ‡ãƒã‚¤ã‚¹ {device} ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            pipe = pipeline(
                "text-generation",
                model=MODEL_NAME,
                model_kwargs={"torch_dtype": torch.bfloat16},
                device=device
            )
        st.success(f"âœ… ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return pipe
    except Exception as e:
        st.error(f"âŒ ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.info("ğŸ’¡ ä¸è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‰ã˜ã‚‹ã‹ã€å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚")
        return None

pipe = llm.load_model()

# --- ãƒ˜ãƒƒãƒ€ãƒ¼ ---
st.markdown(
    """
    <h1 style='text-align: center; color: #4CAF50;'>ğŸ¤– Gemma 2 Chatbot with Feedback</h1>
    <p style='text-align: center;'>Gemmaãƒ¢ãƒ‡ãƒ«ã§å‹•ãã‚¹ãƒãƒ¼ãƒˆãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆä½“é¨“ã¸ã‚ˆã†ã“ãï¼</p>
    <hr>
    """,
    unsafe_allow_html=True
)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("ğŸ“š ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
    st.markdown("---")

    if 'page' not in st.session_state:
        st.session_state.page = "ãƒãƒ£ãƒƒãƒˆ"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ¼ã‚¸

    page = st.radio(
        "ğŸ“„ ãƒšãƒ¼ã‚¸é¸æŠ",
        ["ãƒãƒ£ãƒƒãƒˆ", "å±¥æ­´é–²è¦§", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†"],
        key="page_selector",
        index=["ãƒãƒ£ãƒƒãƒˆ", "å±¥æ­´é–²è¦§", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†"].index(st.session_state.page),
        on_change=lambda: setattr(st.session_state, 'page', st.session_state.page_selector)
    )

    st.markdown("---")
    st.caption("ğŸ› ï¸ é–‹ç™ºè€…: Your Name")

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
if st.session_state.page == "ãƒãƒ£ãƒƒãƒˆ":
    if pipe:
        ui.display_chat_page(pipe)
    else:
        st.error("âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
elif st.session_state.page == "å±¥æ­´é–²è¦§":
    ui.display_history_page()
elif st.session_state.page == "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
    ui.display_data_page()

# --- ãƒ•ãƒƒã‚¿ãƒ¼ï¼ˆä»»æ„ï¼‰ ---
st.markdown(
    """
    <style>
    footer {visibility: hidden;}
    </style>
    """,
    unsafe_allow_html=True
)
