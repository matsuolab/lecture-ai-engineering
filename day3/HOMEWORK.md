# 【第3回】AIエンジニアリング実践 任意課題

## 宿題の概要
この宿題では、講義で学んだRAG (Retrieval-Augmented Generation) 技術を用いて、LLMの生成内容を改善する実践的な取り組みを行います。演習で利用したコードをベースに、独自の質問と参照文書を用いて実験を行い、RAGの効果を定量的・定性的に評価します。

この宿題を通じて、「テストデータの作成」と「改善のプロセス」について理解を深め、実際のアプリケーション開発に役立てることを目指します。

## 宿題の内容
1. **独自の質問と参照資料の作成**  
 * 自分で5つ以上の質問文を考案してください
 * 各質問に対する回答を含む参照文書を用意してください
 * 少なくとも1つは、LLMが単体では正確に答えられないような知識を含む質問にしてください

2. **実験の実施**
 * 演習で使用したコードをベースに、以下の2つの方法で回答を生成してください
    * ベースのLLM（RAGなし）での回答生成  
    * RAGを組み合わせた回答生成  
 * 回答の評価では、単純なYes/No判定でも良いです  
    * より詳細な評価指標も検討していただけるとなお良いです  

3. **結果分析と考察**
 * 生成した結果をまとめ、RAGありとRAGなしの差異を分析してください
 * RAGによって回答が改善したケースと悪化したケースの両方について考察してください
 * 結果に基づいて、RAGの有効性と限界についての考察を記述してください


# 質問設計の観点と意図
扱うモデルを「google/gemma-2-2b-jpn-it」演習と同様としたため、このモデルは、リリース時期の関係上、以下の特徴を持つ。
- tj-actions/changed-files の脆弱性（CVE-2025-30066）情報が広まる前に訓練されており、このトピックに関する知識を持たないと想定される。
- この特性を活かし、純粋なベースライン評価から各手法の効果を観察する。

## 質問設計

以下、2025年3月に発見された tj-actions/changed-files の脆弱性（CVE-2025-30066）をテーマにした質問例を 6 つ挙げる。（モデル単体ではリアルタイムに正確に答えにくい最新情報を含む。）
1. **脆弱性の発生タイムライン**  
   tj-actions/changed-files リポジトリにおいて、悪意あるペイロードが最初にコミットされたのはいつか、またそれが公表されたのはいつか？
2. **攻撃手法と影響範囲**  
  この脆弱性によって GitHub Actions のログに漏洩した具体的な秘密情報（環境変数や認証トークンなど）の例は？
3. **検出・診断方法**  
  既存のリポジトリが影響を受けているかを自動でチェックするために有効なスクリプトやクエリの例は？
4. **修正内容の技術的詳細**  
  悪意あるコードがどのファイル／関数に追加されていたかを示し、修正パッチではどのようにコードが書き換えられた？
5. **公式アドバイザリとドキュメント**  
   GitHub Security Advisory や CISA アラートで公開された、この脆弱性に関する公式ドキュメントの識別子（ID）や URL は？
6. **影響を受けた組織・プロジェクト**  
   実際に被害が報告された主要なオープンソースプロジェクト名や企業名、およびそれらが公開したインシデント報告のリンクは？

## 回答を含む参照文書

1. **脆弱性の発生タイムライン**  
  脆弱性発生タイムラインは、2025年3月12日から15日にかけてtj-actions/changed-filesのタグが悪意あるコミットに差し替えられ、3月14日 StepSecurityが異常検知、3月15日 GitHubがリポジトリを一時非公開化し3月17日にv46.0.1がリリースされた。
2. **撃手法と影響範囲**  
  攻撃手法と漏洩情報は、index.jsに外部Gistからmemdump.pyをダウンロード・実行するコードが注入され、RunnerのメモリをダンプしてAWSキー、GitHub PAT、npmトークン、RSA鍵などをログに書き出した。
3. **検出・診断方法**  
  検出・診断方法は、GitHubコード検索でtj-actions/changed-filesの使用箇所を特定し、Falco ActionsやHarden-Runnerで外部接続を監視し、ログからBase64二重エンコード文字列を抽出してシークレットパターンを検査する。
4. **修正内容の技術的詳細**  
  修正内容は、悪意あるGist取得・実行処理をindex.jsから削除し、action.ymlで外部スクリプト読み込みを禁止、全タグを安全なコミットに再ポイントしてv46.0.1以降をリリースした。
5. **公式アドバイザリとドキュメント**  
  公式アドバイザリは、CVE-2025-30066、GHSA-MRRH-FWG8-R2C3、CISAアラート「Supply Chain Compromise of Third-Party tj-actions/changed-files」（2025-03-18公開）。
6. **影響を受けた組織・プロジェクト**  
  影響を受けた組織は、espressif/arduino-esp32、chains-project/maven-lockfile、rackerlabs/genestack、modal-labs/modal-examplesなど約23,000リポジトリが使用し、公開ログ保持プロジェクトで漏洩が多発し、StepSecurityやAqua Securityが詳細レポートを公開。 　

#### 上記回答を含む参照文書は、以下のリポジトリに格納。  
https://github.com/taitai-2009/lecture-ai-engineering.git  
初期版：Day3 > data > tj-actions-raw.txt  
改良版：Day3 > data > tj-actions.txt  


# RAGの実装方法と工夫点
1. RAGを実装する上で用意した、質問への回答を含む参照文書は、演習にならい、「。」で区切り、トップ5の類似度の文章を参考資料としてプロンプトに挿入した。
2. 続いて、攻撃手法と漏洩した情報について、少し詳しく書いたデータを用意した。このデータも、1と同様の処理を行い、プロンプトに挿入した。
3. 検索結果の品質向上のため、演習にならい、文脈を考慮したチャンク化を導入。前後のチャンクを、2（演習と同様）、3、1と設定し、プロンプトに挿入した。
4. 回答品質の高かった、チャンク数1のケースで、演習にならいRerankを実施し、関連性の高い文章のみプロンプトに挿入した。

#### 上記の詳細、コードおよび結果は、以下のリポジトリのファイルを参照  
https://github.com/taitai-2009/lecture-ai-engineering.git  
ファイル：day3_ai_engineering_03_T4_homework.ipynb
  
  
# 結果の分析と考察

#### 実験に利用したモデル
google/gemma-2-2b-jpn-it (2024年10月リリース)

#### 質問
tj-actions/changed-files の脆弱性によって、悪意あるコードがどのファイル／関数に追加されていたかを示し、この脆弱性により、どのような影響があったか、また、修正パッチではどのようにコードが書き換えられたかを説明してください。

#### 模範回答（OpenAIのgpt-4oで評価に利用)
tj-actions/changed-files 脆弱性の影響は、GitHub Runner のメモリをダンプし、環境変数やプロセス中のシークレットを抽出してビルドログに出力した。この時、AWSキー、GitHub PAT、npmトークン、RSA鍵などをビルドログに書き出した。修正内容は、悪意あるGist取得・実行処理をindex.jsから削除し、action.ymlで外部スクリプト読み込みを禁止、全タグを安全なコミットに再ポイントしてv46.0.1以降をリリースしています。

#### RAG なし （ベースモデル)
* gpt-4oによる評価：0.0  
「google/gemma-2-2b-jpn-it」は「tj-actions/changed-files の脆弱性」について誤った知識を提示。モデルは脆弱性のにより影響を受けたファイルについて具体的な事例がなく、修正ついての回答が一般的な内容となっている。これは、モデルのリリースが2024年10月であり、脆弱性が公表されたのが、2025年3月であるため、このモデルがこの脆弱性の情報を持っていないためと考えられる。

#### RAG導入
* gpt-4oによる評価：3.0  
回答・参照情報のファイル(tj-actions-raw.txt)にある情報を元に、回答の生成ができた。スコアは悪くないが、具体的な影響（何のログへの出力なのか）がわからない。  
回答精度の問題が考えられる。具体的には、脆弱性の悪用により、AWSキー、GitHub PAT、npmトークン、RSA鍵などが何のログに書き出されたのかが明確でない。

#### 回答・参照情報データの品質改善
* gpt-4oによる評価：1.0  
攻撃手法と漏洩情報について、もう少し詳しく書いたデータ(tj-actions.txt)を用意し、上記と同様の処理によりプロンプトを生成し回答を生成。  
テキストの品質改善により、これまでただのログへの出力との記載だったが、公開されているビルドログへの影響が回答された。  
一方で、漏洩した認証情報についての回答がなく、評価スコアも下がった。  
演習にならい、モデルが不十分な回答を生成する要因として、文脈の欠如が考えらとし、「。」で区切られた短い文単位での検索では、各文の発言背景や関連性が失われる
結果として、正しい個別の文でも、その解釈に必要な背景情報が欠如し、誤った文脈で理解される可能性がある。

#### 文脈を考慮したチャンク化の導入(チャンク数２)
* gpt-4oによる評価：2.0  
脆弱性情報に、修正内容が混入。具体的な漏洩データが、修正内容として回答している。

#### 文脈を考慮したチャンク化の導入(チャンク数３)
* gpt-4oによる評価：2.0  
脆弱性内容が細かく分類されたが、内容としては、チャンク数2の時と同様で、脆弱性情報に、修正内容が混入。具体的な漏洩データが、修正内容として回答している。

#### 文脈を考慮したチャンク化の導入(チャンク数1)
* gpt-4oによる評価：2.0  
脆弱性の影響が出たタイムラインから始まっており、具体的な漏洩データが、影響として回答されるようになった。修正内容も正確。一方で、悪意のあるコードの追加、コードの書き換えの回答として、冗長感あり。  
**今回の実験では、この出力が主観的に最もフィットする。**

#### Rerankによる情報品質の向上(チャンク数1)
* gpt-4oによる評価：2.0  
回答出力が全体として冗長感はなくコンパクトになり、回答としては過不足ない。一方で、悪意あるコードの追加に、漏洩データが記載されてしまっている。

#### RAGによって回答が改善したケースと悪化したケース
* RAGとして追加するテキストに詳しい情報を与えたり、チャンク数を２や3とするよりも、1とした時の方が回答が改善することがわかった。ただし、出力される文章が正しい箇所に出ていないケースあり。  
* 上記の改善、改悪については、gpt-4oによる評価スコアに反映されていなかった。スコアリングに改善の余地があると思われる。
  
  
#### RAGの有効性と限界
有効性
* 事実性（Factuality）の向上  
  モデル単体では記憶外の最新データや固有名詞を参照できずに起きる誤答を、外部ドキュメントを根拠に修正できる。
* ドメイン適応性  
  業界レポートやマニュアルなど、特定領域の資料をそのまま取り込むことで、ゼロショット性能を大きく超える専門回答が可能。
* メンテナンス性  
  ドキュメントを更新するだけで回答内容をアップデートでき、モデル再学習なしに知識の鮮度維持が容易。

限界  
* リトリーバル品質への依存  
  関連性スコアや分割方法のチューニングが不十分だと、不要情報を拾ったり、逆に必要情報を漏らしたりして回答品質が不安定。
* オーバーヘッド  
  埋め込み生成＋ベクトル検索＋モデル呼び出しの３段階処理のため、レイテンシや計算コストが増大。特にエッジ環境では負荷が大きい。
* ドキュメント設計の難しさ  
  チャンクの粒度やメタデータ設計を誤ると、文脈が切れて誤答を誘発しやすい。最適粒度の探索コストが高い。
* セキュリティ・プライバシーリスク  
  機密情報含む文書をまるごと投入すると、意図せず機密流出を招く可能性があるため、ドキュメント管理とアクセス制御が必須。

